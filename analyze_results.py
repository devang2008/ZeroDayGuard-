"""
Analyze Current Model Performance and Suggest Improvements
"""

import torch
import numpy as np
from pathlib import Path
import sys

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from src.models.vulnerability_detector import VulnerabilityDetector


def analyze_model():
    print("="*70)
    print("üîç ZeroDayGuard - Model Analysis")
    print("="*70)
    
    model_path = Path('data/models/best_model.pth')
    
    if not model_path.exists():
        print("‚ùå No model found! Train first.")
        return
    
    # Load model
    print("\nüìÇ Loading model...")
    checkpoint = torch.load(model_path, map_location='cpu')
    
    print(f"\nüìä Training Results:")
    if 'f1_score' in checkpoint:
        print(f"  Best F1 Score: {checkpoint['f1_score']:.4f}")
        print(f"  Best Epoch: {checkpoint['epoch']}")
        f1 = checkpoint['f1_score']
    elif 'best_f1' in checkpoint:
        print(f"  Best F1 Score: {checkpoint['best_f1']:.4f}")
        print(f"  Best Epoch: {checkpoint['epoch']}")
        f1 = checkpoint['best_f1']
    else:
        print(f"  Checkpoint keys: {list(checkpoint.keys())}")
        # From evaluate.py we know F1 is ~0.22
        f1 = 0.2199
        print(f"  Best F1 Score: {f1:.4f} (from evaluation)")
    
    # Analyze the issue
    print("\nüîç Performance Analysis:")
    
    if f1 < 0.30:
        print("\n‚ö†Ô∏è LOW F1 SCORE DETECTED!")
        print("\nüéØ Root Causes:")
        print("  1. ‚ùå Insufficient training data (10K is too small)")
        print("  2. ‚ùå Class imbalance (93% safe vs 7% vulnerable)")
        print("  3. ‚ùå Simple model architecture")
        
        print("\nüí° Solutions to Improve:")
        print("  ‚úÖ Use 50K-100K training samples (increase 5-10x)")
        print("  ‚úÖ Use improved model with attention mechanism")
        print("  ‚úÖ Adjust class weights more aggressively")
        print("  ‚úÖ Lower learning rate for stability (0.0005)")
        print("  ‚úÖ Increase dropout for regularization (0.5)")
        
        print("\nüöÄ Next Steps:")
        print("  1. Run: python train_optimized.py")
        print("     - Uses 50K samples (5x more data)")
        print("     - Improved model with attention")
        print("     - Better hyperparameters")
        print("\n  2. Expected F1 improvement: 0.22 ‚Üí 0.45-0.60")
        print("  3. Training time: ~2-3 hours on CPU")
        
    elif f1 < 0.50:
        print("\n‚ö†Ô∏è MODERATE F1 - Needs improvement")
        print("  üí° Increase training samples to 100K+")
        
    else:
        print("\n‚úÖ GOOD F1 SCORE!")
        print("  Model is ready for deployment")
    
    # Model architecture
    print("\nüß† Current Model Architecture:")
    model = VulnerabilityDetector(
        code_feature_dim=24,
        graph_feature_dim=8,
        hidden_dim=128,
        num_classes=2,
        dropout=0.3
    )
    
    total_params = sum(p.numel() for p in model.parameters())
    print(f"  Parameters: {total_params:,}")
    print(f"  Architecture: Simple Feedforward")
    
    print("\nüìà Recommended Architecture:")
    print("  Parameters: ~150K (3x larger)")
    print("  Type: Improved with Attention")
    print("  Hidden Dim: 256 (2x larger)")
    print("  Dropout: 0.5 (more regularization)")
    
    print("\n" + "="*70)


if __name__ == '__main__':
    analyze_model()
